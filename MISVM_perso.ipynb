{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LouisStefanuto/Detection-of-the-PIK3CA-mutation-in-breast-cancer/blob/MISVM/MISVM_perso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWRvJehBIVCZ"
      },
      "source": [
        "## Notebook using MISVM approach\n",
        "\n",
        "Une idee à tester ça serait de reprendre ce code pour un autre classifieur :\n",
        "\n",
        "1. Initialiser les tiles avec le label de leur bag\n",
        "\n",
        "2. Fit un modèle de régression dessus (SVM)\n",
        "\n",
        "3. Update les poids des tiles bags positifs par sgn(prédiction) et pour la tile \n",
        "avec la plus grande proba la mettre à 1\n",
        "\n",
        "4. Si pas de changement de label, STOP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBdk3-NBIVCc"
      },
      "source": [
        "Before starting, you will need to install some packages to reproduce the baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:49.282534Z",
          "start_time": "2022-10-24T07:22:35.359325Z"
        },
        "id": "AEZnKfE6IVCd"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os"
      ],
      "metadata": {
        "id": "ELeCLoyNJJGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import data\n",
        "PATH_COLAB = '/content/drive/MyDrive/challenge_ens_2023_small/moco_features.zip'\n",
        "PATH_DEVICE = '..'\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    logging.info('Working on Colab.')\n",
        "    \n",
        "    # connect your drive to the session\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    %cd /content/drive/MyDrive/challenge_data_ens_small/\n",
        "\n",
        "    # unzip data into the colab session\n",
        "    ! unzip $PATH_COLAB -d /content\n",
        "    logging.info('Data unziped in your Drive.')\n",
        "\n",
        "    %cd /content\n",
        "\n",
        "    %cp -R drive/MyDrive/challenge_ens_2023_small/supplementary_data/ .\n",
        "    %cp drive/MyDrive/challenge_ens_2023_small/train_output.csv .\n",
        "\n",
        "\n",
        "except:\n",
        "    logging.info('Working on your device.')\n",
        "    \n",
        "    data_exists = os.path.exists(PATH_DEVICE + '/train_input') and os.path.exists(PATH_DEVICE + '/test_input') and os.path.exists(PATH_DEVICE + '/train_output.csv')\n",
        "    \n",
        "    if data_exists:\n",
        "        logging.info(f\"Dataset found on device at : '{PATH_DEVICE}.'\") \n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Data folder not found at '{PATH_DEVICE}'\")"
      ],
      "metadata": {
        "id": "_KeubXuWIdt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls ."
      ],
      "metadata": {
        "id": "5SS6fpk0PyTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:50.448803Z",
          "start_time": "2022-10-24T07:22:49.285830Z"
        },
        "id": "ZVVx7TstIVCe"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-heudtBaIVCf"
      },
      "source": [
        "# Data architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T15:29:41.479814Z",
          "start_time": "2022-10-20T15:29:41.472869Z"
        },
        "id": "545DA7nwIVCg"
      },
      "source": [
        "After downloading or unzipping the downloaded files, your data tree must have the following architecture in order to properly run the notebook:\n",
        "```\n",
        "your_data_dir/\n",
        "├── train_output.csv\n",
        "├── train_input/\n",
        "│   ├── images/\n",
        "│       ├── ID_001/\n",
        "│           ├── ID_001_tile_000_17_170_43.jpg\n",
        "...\n",
        "│   └── moco_features/\n",
        "│       ├── ID_001.npy\n",
        "...\n",
        "├── test_input/\n",
        "│   ├── images/\n",
        "│       ├── ID_003/\n",
        "│           ├── ID_003_tile_000_16_114_93.jpg\n",
        "...\n",
        "│   └── moco_features/\n",
        "│       ├── ID_003.npy\n",
        "...\n",
        "├── supplementary_data/\n",
        "│   ├── baseline.ipynb\n",
        "│   ├── test_metadata.csv\n",
        "│   └── train_metadata.csv\n",
        "```\n",
        "\n",
        "For instance, `your_data_dir = /storage/DATA_CHALLENGE_ENS_2022/`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQF2ZjUKIVCh"
      },
      "source": [
        "This notebook aims to reproduce the baseline method on this challenge called `MeanPool`. This method consists in a logistic regression learnt on top of tile-level MoCo V2 features averaged over the slides.\n",
        "\n",
        "For a given slide $s$ with $N_s=1000$ tiles and corresponding MoCo V2 features $\\mathbf{K_s} \\in \\mathbb{R}^{(1000,\\,2048)}$, a slide-level average is performed over the tile axis.\n",
        "\n",
        "For $j=1,...,2048$:\n",
        "\n",
        "$$\\overline{\\mathbf{k_s}}(j) = \\frac{1}{N_s} \\sum_{i=1}^{N_s} \\mathbf{K_s}(i, j) $$\n",
        "\n",
        "Thus, the training input data for MeanPool consists of $S_{\\text{train}}=344$ mean feature vectors $\\mathbf{k_s}$, $s=1,...,S_{\\text{train}}$, where $S_{\\text{train}}$ denotes the number of training samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T09:25:58.896288Z",
          "start_time": "2022-10-20T09:25:58.161711Z"
        },
        "id": "vHFZ1LzqIVCi"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:50.479040Z",
          "start_time": "2022-10-24T07:22:50.450662Z"
        },
        "id": "GyJAXeeJIVCi"
      },
      "outputs": [],
      "source": [
        "# put your own path to the data root directory (see example in `Data architecture` section)\n",
        "data_dir = Path(\"./\")\n",
        "\n",
        "# load the training and testing data sets\n",
        "train_features_dir = data_dir / \"train_input\" / \"moco_features\"\n",
        "test_features_dir = data_dir / \"test_input\" / \"moco_features\"\n",
        "df_train = pd.read_csv(data_dir  / \"supplementary_data\" / \"train_metadata.csv\")\n",
        "df_test = pd.read_csv(data_dir  / \"supplementary_data\" / \"test_metadata.csv\")\n",
        "\n",
        "# concatenate y_train and df_train\n",
        "y_train = pd.read_csv(data_dir  / \"train_output.csv\")\n",
        "df_train = df_train.merge(y_train, on=\"Sample ID\")\n",
        "\n",
        "print(f\"Training data dimensions: {df_train.shape}\")  # (344, 4)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZZdjmeKIVCk"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlJo2KRDIVCl"
      },
      "source": [
        "We now load the features matrices $\\mathbf{K_s} \\in \\mathbb{R}^{(1000,\\,2048)}$ for $s=1,...,344$ and perform slide-level averaging. This operation should take at most 5 minutes on your laptop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:52.890700Z",
          "start_time": "2022-10-24T07:22:50.480795Z"
        },
        "id": "TpTCbbryIVCm"
      },
      "outputs": [],
      "source": [
        "size_train = len(df_train)\n",
        "X_train = np.zeros((size_train, 2048))\n",
        "y_train = np.zeros((size_train))\n",
        "\n",
        "centers_train = []\n",
        "patients_train = []\n",
        "\n",
        "\n",
        "for i, (sample, label, center, patient) in enumerate(tqdm(\n",
        "    df_train[[\"Sample ID\", \"Target\", \"Center ID\", \"Patient ID\"]].values\n",
        ")):\n",
        "    if i >= size_train:\n",
        "      break\n",
        "    # load the coordinates and features (1000, 3+2048)\n",
        "    _features = np.load(train_features_dir / sample)\n",
        "    # get coordinates (zoom level, tile x-coord on the slide, tile y-coord on the slide)\n",
        "    # and the MoCo V2 features\n",
        "    coordinates, features = _features[:, :3], _features[:, 3:]  # Ks\n",
        "    # slide-level averaging\n",
        "    X_train[i] = np.mean(features, axis=0)\n",
        "    y_train[i] = label\n",
        "    centers_train.append(center)\n",
        "    patients_train.append(patient)\n",
        "\n",
        "centers_train = np.array(centers_train)\n",
        "patients_train = np.array(patients_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MI-SVM approach"
      ],
      "metadata": {
        "id": "TK_38qyHY-0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "def train_MISVM(df, features_dir):\n",
        "    svm = SVC(kernel='rbf', gamma=0.37, C = 0.1, probability=True)\n",
        "\n",
        "    size = len(df)\n",
        "    X_S_I = np.zeros((size, 2048))\n",
        "    Y_I = np.zeros((size))\n",
        "\n",
        "\n",
        "    for i, (sample, label, _, _) in enumerate(tqdm(\n",
        "        df[[\"Sample ID\", \"Target\", \"Center ID\", \"Patient ID\"]].values\n",
        "    )):\n",
        "        # load the coordinates and features (1000, 3+2048)\n",
        "        _features = np.load(features_dir / sample)\n",
        "        # get coordinates (zoom level, tile x-coord on the slide, tile y-coord on the slide)\n",
        "        # and the MoCo V2 features\n",
        "        coordinates, features = _features[:, :3], _features[:, 3:]  # Ks\n",
        "        # slide-level averaging\n",
        "        X_S_I[i] = np.mean(features, axis=0)\n",
        "        Y_I[i] = label\n",
        "\n",
        "    S_I = - np.ones(len(X_train), dtype=int)\n",
        "\n",
        "    changes = 1\n",
        "    while changes > 0:\n",
        "\n",
        "        svm.fit(X_S_I, Y_I)\n",
        "\n",
        "        changes = 0\n",
        "\n",
        "        for bag, (sample, label, _, _) in enumerate(tqdm(\n",
        "            df[[\"Sample ID\", \"Target\", \"Center ID\", \"Patient ID\"]].values\n",
        "        )):\n",
        "            if label:\n",
        "                # load the coordinates and features (1000, 3+2048)\n",
        "                _features = np.load(features_dir / sample)\n",
        "                features = _features[:, 3:]  # Ks\n",
        "\n",
        "                # compute classification score for each tile\n",
        "                f_i = svm.predict_proba(features)[:,1]\n",
        "                new_S = np.argmax(f_i)\n",
        "\n",
        "                if new_S != S_I[bag]:\n",
        "                    S_I[bag] = new_S\n",
        "                    X_train[bag] = features[new_S]\n",
        "                    changes += 1\n",
        "\n",
        "        print(f\"Changes : {changes}\")\n",
        "\n",
        "    return svm"
      ],
      "metadata": {
        "id": "-O4nRcy1NVLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_MISVM(model, df, features_dir):\n",
        "\n",
        "    preds = np.zeros(len(df))\n",
        "\n",
        "    for bag, (sample, _, _) in enumerate(tqdm(\n",
        "            df[[\"Sample ID\", \"Center ID\", \"Patient ID\"]].values\n",
        "        )):\n",
        "            # load the coordinates and features (1000, 3+2048)\n",
        "            _features = np.load(features_dir / sample)\n",
        "            features = _features[:, 3:]  # Ks\n",
        "\n",
        "            # compute classification score for each tile\n",
        "            f_i = model.predict_proba(features)[:,1]\n",
        "            preds[bag] = np.max(f_i)\n",
        "    return preds"
      ],
      "metadata": {
        "id": "_tV6gfPBZoNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#svm = train_MISVM(df_train, train_features_dir)"
      ],
      "metadata": {
        "id": "SZks9tjZaGNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preds = eval_MISVM(svm, df_train, train_features_dir)"
      ],
      "metadata": {
        "id": "6E4ipdD0acyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:52.905566Z",
          "start_time": "2022-10-24T07:22:52.893435Z"
        },
        "id": "wnkt-QvJIVCq"
      },
      "outputs": [],
      "source": [
        "# /!\\ we perform splits at the patient level so that all samples from the same patient\n",
        "# are found in the same split\n",
        "\n",
        "patients_unique = np.unique(patients_train)\n",
        "\n",
        "y_unique = np.array(\n",
        "    [np.mean(y_train[patients_train == p]) for p in patients_unique]\n",
        ")\n",
        "centers_unique = np.array(\n",
        "    [centers_train[patients_train == p][0] for p in patients_unique]\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Training set specifications\\n\"\n",
        "    \"---------------------------\\n\"\n",
        "    f\"{len(X_train)} unique samples\\n\"\n",
        "    f\"{len(patients_unique)} unique patients\\n\"\n",
        "    f\"{len(np.unique(centers_unique))} unique centers\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:54.077640Z",
          "start_time": "2022-10-24T07:22:52.907331Z"
        },
        "id": "YnF1FRXnIVCq"
      },
      "outputs": [],
      "source": [
        "aucs = []\n",
        "models = []\n",
        "# 5-fold CV is repeated 5 times with different random states\n",
        "for k in range(5):\n",
        "    kfold = StratifiedKFold(5, shuffle=True, random_state=k)\n",
        "    fold = 0\n",
        "    # split is performed at the patient-level\n",
        "    for train_idx_, val_idx_ in kfold.split(patients_unique, y_unique):\n",
        "        # retrieve the indexes of the samples corresponding to the\n",
        "        # patients in `train_idx_` and `test_idx_`\n",
        "        train_idx = np.arange(len(X_train))[\n",
        "            pd.Series(patients_train).isin(patients_unique[train_idx_])\n",
        "        ]\n",
        "        val_idx = np.arange(len(X_train))[\n",
        "            pd.Series(patients_train).isin(patients_unique[val_idx_])\n",
        "        ]\n",
        "        # set the training and validation folds\n",
        "        df = df_train.iloc[train_idx]\n",
        "        df_val = df_train.iloc[val_idx]\n",
        "\n",
        "        y_fold_val = df_val[\"Target\"]\n",
        "        \n",
        "        # instantiate and fit a SVM via MISVM\n",
        "        svm = train_MISVM(df, train_features_dir)\n",
        "\n",
        "        # get the predictions (1-d probability)\n",
        "        preds_val = eval_MISVM(svm, df_val, train_features_dir)\n",
        "\n",
        "\n",
        "        # compute the AUC score using scikit-learn\n",
        "        auc = roc_auc_score(y_fold_val, preds_val)\n",
        "        print(f\"AUC on split {k} fold {fold}: {auc:.3f}\")\n",
        "        aucs.append(auc)\n",
        "        # add the logistic regression to the list of classifiers\n",
        "        models.append(svm)\n",
        "        fold += 1\n",
        "    print(\"----------------------------\")\n",
        "print(\n",
        "    f\"5-fold cross-validated AUC averaged over {k+1} repeats: \"\n",
        "    f\"{np.mean(aucs):.3f} ({np.std(aucs):.3f})\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RpJjp8QIVCq"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gQfQfv5IVCr"
      },
      "source": [
        "Now we evaluate the previous models trained through cross-validation so that to produce a submission file that can directly be uploaded on the data challenge platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T08:17:35.617554Z",
          "start_time": "2022-10-20T08:17:35.603562Z"
        },
        "id": "uuDWghTAIVCs"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:55.043255Z",
          "start_time": "2022-10-24T07:22:54.989274Z"
        },
        "id": "gl5YQBcfIVCs"
      },
      "outputs": [],
      "source": [
        "preds_test = 0\n",
        "# loop over the classifiers\n",
        "for svm in models:\n",
        "    preds_test += eval_MISVM(svm, df_test, test_features_dir)\n",
        "\n",
        "# and take the average (ensembling technique)\n",
        "preds_test = preds_test / len(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P9DpnkDIVCt"
      },
      "source": [
        "## Saving predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:55.098571Z",
          "start_time": "2022-10-24T07:22:55.044975Z"
        },
        "id": "gEb_tbQRIVCt"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame(\n",
        "    {\"Sample ID\": df_test[\"Sample ID\"].values, \"Target\": preds_test}\n",
        ").sort_values(\n",
        "    \"Sample ID\"\n",
        ")  # extra step to sort the sample IDs\n",
        "\n",
        "# sanity checks\n",
        "assert all(submission[\"Target\"].between(0, 1)), \"`Target` values must be in [0, 1]\"\n",
        "assert submission.shape == (149, 2), \"Your submission file must be of shape (149, 2)\"\n",
        "assert list(submission.columns) == [\n",
        "    \"Sample ID\",\n",
        "    \"Target\",\n",
        "], \"Your submission file must have columns `Sample ID` and `Target`\"\n",
        "\n",
        "\n",
        "file_name = \"benchmark_test_output_MISVM_rbf_kernel.csv\"\n",
        "# save the submission as a csv file\n",
        "submission.to_csv(data_dir / file_name, index=None)\n",
        "\n",
        "%cp ./$file_name /content/drive/MyDrive/challenge_ens_2023_small/$file_name\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfb4YBULIVCt"
      },
      "source": [
        "# Dealing with images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnXwsxG6IVCt"
      },
      "source": [
        "The following code aims to load and manipulate the images provided as part of  this challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3j3wpElIVCt"
      },
      "source": [
        "## Scanning images paths on disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZWffnZ2IVCu"
      },
      "source": [
        "This operation can take up to 5 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:00.263580Z",
          "start_time": "2022-10-24T07:22:55.100342Z"
        },
        "id": "FuPctezJIVCu"
      },
      "outputs": [],
      "source": [
        "train_images_dir = data_dir / \"train_input\" / \"images\"\n",
        "train_images_files = list(train_images_dir.rglob(\"*.jpg\"))\n",
        "\n",
        "test_images_dir = data_dir / \"test_input\" / \"images\"\n",
        "test_images_files = list(test_images_dir.rglob(\"*.jpg\"))\n",
        "\n",
        "print(\n",
        "    f\"Number of images\\n\"\n",
        "    \"-----------------\\n\"\n",
        "    f\"Train: {len(train_images_files)}\\n\" # 344 x 1000 = 344,000 tiles\n",
        "    f\"Test: {len(test_images_files)}\\n\"  # 149 x 1000 = 149,000 tiles\n",
        "    f\"Total: {len(train_images_files) + len(test_images_files)}\\n\"  # 493 x 1000 = 493,000 tiles\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T10:16:48.078600Z",
          "start_time": "2022-10-20T10:16:47.948127Z"
        },
        "id": "KysISjJqIVCv"
      },
      "source": [
        "## Reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj8oNBRWIVCv"
      },
      "source": [
        "Now we can load some of the `.jpg` images for a given sample, say `ID_001`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:00.381225Z",
          "start_time": "2022-10-24T07:23:00.267047Z"
        },
        "id": "PUrmGZbLIVCv"
      },
      "outputs": [],
      "source": [
        "ID_001_tiles = [p for p in train_images_files if 'ID_001' in p.name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:01.973155Z",
          "start_time": "2022-10-24T07:23:00.382760Z"
        },
        "id": "542unP3XIVCv"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(5, 5)\n",
        "fig.set_size_inches(12, 12)\n",
        "\n",
        "for i, img_file in enumerate(ID_001_tiles[:25]):\n",
        "    # get the metadata from the file path\n",
        "    _, metadata = str(img_file).split(\"tile_\")\n",
        "    id_tile, level, x, y = metadata[:-4].split(\"_\")\n",
        "    img = plt.imread(img_file)\n",
        "    ax = axes[i//5, i%5]\n",
        "    ax.imshow(img)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_title(f\"Tile {id_tile} ({x}, {y})\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NDmCKBmIVCw"
      },
      "source": [
        "## Mapping with features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWbnMr9jIVCw"
      },
      "source": [
        "Note that the coordinates in the features matrices and tiles number are aligned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:01.984327Z",
          "start_time": "2022-10-24T07:23:01.974933Z"
        },
        "id": "vShB69UoIVCx"
      },
      "outputs": [],
      "source": [
        "sample = \"ID_001.npy\"\n",
        "_features = np.load(train_features_dir / sample)\n",
        "coordinates, features = _features[:, :3], _features[:, 3:]\n",
        "print(\"xy features coordinates\")\n",
        "coordinates[:10, 1:].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:01.990342Z",
          "start_time": "2022-10-24T07:23:01.985926Z"
        },
        "id": "k0MBXPMaIVCx"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    \"Tiles numbering and features coordinates\\n\"\n",
        ")\n",
        "[tile.name for tile in ID_001_tiles[:10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0A02vL48IVCx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuvYhfBlIVCx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}