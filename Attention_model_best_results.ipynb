{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LouisStefanuto/Detection-of-the-PIK3CA-mutation-in-breast-cancer/blob/main/Attention_model_best_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkOUh2HptHjx"
      },
      "source": [
        "Before starting, you will need to install some packages to reproduce the baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:49.282534Z",
          "start_time": "2022-10-24T07:22:35.359325Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYHxK0njtHjz",
        "outputId": "0e291a30-5609-4e73-c612-d9daf198f401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:50.448803Z",
          "start_time": "2022-10-24T07:22:49.285830Z"
        },
        "id": "L4-Z4UoCtHj0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxW2WuijtHj2",
        "outputId": "2549f287-5bbd-4646-93ba-85fdef8e02f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/challenge_data_ens_small/'\n",
            "/content\n",
            "Archive:  /content/drive/MyDrive/challenge_ens_2023_small/moco_features.zip\n",
            "  inflating: /content/test_input/.DS_Store  \n",
            "   creating: /content/test_input/moco_features/\n",
            "  inflating: /content/test_input/moco_features/ID_003.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_004.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_008.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_009.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_010.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_011.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_015.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_017.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_022.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_027.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_029.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_030.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_034.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_036.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_038.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_043.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_044.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_047.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_051.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_060.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_065.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_070.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_071.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_078.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_079.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_085.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_103.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_104.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_105.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_107.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_119.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_121.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_125.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_127.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_133.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_135.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_136.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_137.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_140.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_142.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_143.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_144.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_149.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_152.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_157.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_158.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_159.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_162.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_169.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_175.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_177.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_181.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_183.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_189.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_194.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_195.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_198.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_199.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_200.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_207.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_208.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_210.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_212.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_214.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_216.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_219.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_222.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_223.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_224.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_225.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_232.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_234.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_239.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_241.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_246.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_247.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_250.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_255.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_261.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_262.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_267.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_273.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_280.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_281.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_283.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_284.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_285.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_291.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_292.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_294.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_297.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_299.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_300.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_302.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_303.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_311.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_315.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_319.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_322.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_330.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_332.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_333.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_338.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_339.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_342.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_345.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_350.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_354.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_357.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_360.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_364.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_370.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_374.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_376.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_378.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_380.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_381.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_382.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_384.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_385.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_386.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_387.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_388.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_393.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_394.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_395.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_397.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_405.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_413.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_417.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_418.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_424.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_428.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_429.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_438.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_443.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_445.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_447.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_449.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_453.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_457.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_466.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_471.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_473.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_482.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_487.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_488.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_492.npy  \n",
            "  inflating: /content/test_input/moco_features/ID_493.npy  \n",
            "  inflating: /content/train_input/.DS_Store  \n",
            "   creating: /content/train_input/moco_features/\n",
            "  inflating: /content/train_input/moco_features/ID_001.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_002.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_005.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_006.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_007.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_012.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_013.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_014.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_016.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_018.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_019.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_020.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_021.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_023.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_024.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_025.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_026.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_028.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_031.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_032.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_033.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_035.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_037.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_039.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_040.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_041.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_042.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_045.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_046.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_048.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_049.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_050.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_052.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_053.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_054.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_055.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_056.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_057.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_058.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_059.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_061.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_062.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_063.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_064.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_066.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_067.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_068.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_069.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_072.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_073.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_074.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_075.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_076.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_077.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_080.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_081.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_082.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_083.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_084.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_086.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_087.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_088.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_089.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_090.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_091.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_092.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_093.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_094.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_095.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_096.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_097.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_098.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_099.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_100.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_101.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_102.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_106.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_108.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_109.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_110.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_111.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_112.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_113.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_114.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_115.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_116.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_117.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_118.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_120.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_122.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_123.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_124.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_126.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_128.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_129.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_130.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_131.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_132.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_134.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_138.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_139.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_141.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_145.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_146.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_147.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_148.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_150.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_151.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_153.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_154.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_155.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_156.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_160.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_161.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_163.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_164.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_165.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_166.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_167.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_168.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_170.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_171.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_172.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_173.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_174.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_176.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_178.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_179.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_180.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_182.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_184.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_185.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_186.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_187.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_188.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_190.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_191.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_192.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_193.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_196.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_197.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_201.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_202.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_203.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_204.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_205.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_206.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_209.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_211.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_213.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_215.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_217.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_218.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_220.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_221.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_226.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_227.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_228.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_229.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_230.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_231.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_233.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_235.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_236.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_237.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_238.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_240.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_242.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_243.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_244.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_245.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_248.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_249.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_251.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_252.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_253.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_254.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_256.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_257.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_258.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_259.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_260.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_263.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_264.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_265.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_266.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_268.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_269.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_270.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_271.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_272.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_274.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_275.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_276.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_277.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_278.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_279.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_282.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_286.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_287.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_288.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_289.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_290.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_293.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_295.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_296.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_298.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_301.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_304.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_305.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_306.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_307.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_308.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_309.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_310.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_312.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_313.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_314.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_316.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_317.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_318.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_320.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_321.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_323.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_324.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_325.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_326.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_327.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_328.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_329.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_331.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_334.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_335.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_336.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_337.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_340.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_341.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_343.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_344.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_346.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_347.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_348.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_349.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_351.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_352.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_353.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_355.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_356.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_358.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_359.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_361.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_362.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_363.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_365.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_366.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_367.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_368.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_369.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_371.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_372.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_373.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_375.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_377.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_379.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_383.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_389.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_390.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_391.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_392.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_396.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_398.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_399.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_400.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_401.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_402.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_403.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_404.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_406.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_407.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_408.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_409.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_410.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_411.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_412.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_414.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_415.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_416.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_419.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_420.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_421.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_422.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_423.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_425.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_426.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_427.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_430.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_431.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_432.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_433.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_434.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_435.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_436.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_437.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_439.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_440.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_441.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_442.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_444.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_446.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_448.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_450.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_451.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_452.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_454.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_455.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_456.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_458.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_459.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_460.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_461.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_462.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_463.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_464.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_465.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_467.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_468.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_469.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_470.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_472.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_474.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_475.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_476.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_477.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_478.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_479.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_480.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_481.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_483.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_484.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_485.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_486.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_489.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_490.npy  \n",
            "  inflating: /content/train_input/moco_features/ID_491.npy  \n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# import data\n",
        "PATH_COLAB = '/content/drive/MyDrive/challenge_ens_2023_small/moco_features.zip'\n",
        "PATH_DEVICE = '..'\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    logging.info('Working on Colab.')\n",
        "    \n",
        "    # connect your drive to the session\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    %cd /content/drive/MyDrive/challenge_data_ens_small/\n",
        "\n",
        "    # unzip data into the colab session\n",
        "    ! unzip $PATH_COLAB -d /content\n",
        "    logging.info('Data unziped in your Drive.')\n",
        "\n",
        "    %cd /content\n",
        "\n",
        "    %cp -R drive/MyDrive/challenge_ens_2023_small/supplementary_data/ .\n",
        "    %cp drive/MyDrive/challenge_ens_2023_small/train_output.csv .\n",
        "\n",
        "\n",
        "except:\n",
        "    logging.info('Working on your device.')\n",
        "    \n",
        "    data_exists = os.path.exists(PATH_DEVICE + '/train_input') and os.path.exists(PATH_DEVICE + '/test_input') and os.path.exists(PATH_DEVICE + '/train_output.csv')\n",
        "    \n",
        "    if data_exists:\n",
        "        logging.info(f\"Dataset found on device at : '{PATH_DEVICE}.'\") \n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Data folder not found at '{PATH_DEVICE}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwNiwkdUtHj4",
        "outputId": "f3a3cafe-0dfb-479e-9f7e-839dd27dad4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g561bAvWtHj4"
      },
      "source": [
        "# Data architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T15:29:41.479814Z",
          "start_time": "2022-10-20T15:29:41.472869Z"
        },
        "id": "HTGcDg_OtHj5"
      },
      "source": [
        "After downloading or unzipping the downloaded files, your data tree must have the following architecture in order to properly run the notebook:\n",
        "```\n",
        "your_data_dir/\n",
        "├── train_output.csv\n",
        "├── train_input/\n",
        "│   ├── images/\n",
        "│       ├── ID_001/\n",
        "│           ├── ID_001_tile_000_17_170_43.jpg\n",
        "...\n",
        "│   └── moco_features/\n",
        "│       ├── ID_001.npy\n",
        "...\n",
        "├── test_input/\n",
        "│   ├── images/\n",
        "│       ├── ID_003/\n",
        "│           ├── ID_003_tile_000_16_114_93.jpg\n",
        "...\n",
        "│   └── moco_features/\n",
        "│       ├── ID_003.npy\n",
        "...\n",
        "├── supplementary_data/\n",
        "│   ├── baseline.ipynb\n",
        "│   ├── test_metadata.csv\n",
        "│   └── train_metadata.csv\n",
        "```\n",
        "\n",
        "For instance, `your_data_dir = /storage/DATA_CHALLENGE_ENS_2022/`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYiFEHvttHj6"
      },
      "source": [
        "This notebook aims to reproduce the baseline method on this challenge called `MeanPool`. This method consists in a logistic regression learnt on top of tile-level MoCo V2 features averaged over the slides.\n",
        "\n",
        "For a given slide $s$ with $N_s=1000$ tiles and corresponding MoCo V2 features $\\mathbf{K_s} \\in \\mathbb{R}^{(1000,\\,2048)}$, a slide-level average is performed over the tile axis.\n",
        "\n",
        "For $j=1,...,2048$:\n",
        "\n",
        "$$\\overline{\\mathbf{k_s}}(j) = \\frac{1}{N_s} \\sum_{i=1}^{N_s} \\mathbf{K_s}(i, j) $$\n",
        "\n",
        "Thus, the training input data for MeanPool consists of $S_{\\text{train}}=344$ mean feature vectors $\\mathbf{k_s}$, $s=1,...,S_{\\text{train}}$, where $S_{\\text{train}}$ denotes the number of training samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T09:25:58.896288Z",
          "start_time": "2022-10-20T09:25:58.161711Z"
        },
        "id": "HWlYU146tHj6"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:50.479040Z",
          "start_time": "2022-10-24T07:22:50.450662Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "nqplkW7RtHj7",
        "outputId": "5fafa50e-6438-4c5e-c122-e88d507604b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data dimensions: (344, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sample ID Patient ID Center ID  Target\n",
              "0  ID_001.npy      P_001       C_1       0\n",
              "1  ID_002.npy      P_002       C_2       1\n",
              "2  ID_005.npy      P_005       C_5       0\n",
              "3  ID_006.npy      P_006       C_5       0\n",
              "4  ID_007.npy      P_007       C_2       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80981778-f8ea-4554-a0a6-56da017111ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample ID</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Center ID</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_001.npy</td>\n",
              "      <td>P_001</td>\n",
              "      <td>C_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_002.npy</td>\n",
              "      <td>P_002</td>\n",
              "      <td>C_2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_005.npy</td>\n",
              "      <td>P_005</td>\n",
              "      <td>C_5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_006.npy</td>\n",
              "      <td>P_006</td>\n",
              "      <td>C_5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_007.npy</td>\n",
              "      <td>P_007</td>\n",
              "      <td>C_2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80981778-f8ea-4554-a0a6-56da017111ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80981778-f8ea-4554-a0a6-56da017111ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80981778-f8ea-4554-a0a6-56da017111ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# put your own path to the data root directory (see example in `Data architecture` section)\n",
        "data_dir = Path(\"./\")\n",
        "\n",
        "# load the training and testing data sets\n",
        "train_features_dir = data_dir / \"train_input\" / \"moco_features\"\n",
        "test_features_dir = data_dir / \"test_input\" / \"moco_features\"\n",
        "df_train = pd.read_csv(data_dir  / \"supplementary_data\" / \"train_metadata.csv\")\n",
        "df_test = pd.read_csv(data_dir  / \"supplementary_data\" / \"test_metadata.csv\")\n",
        "\n",
        "# concatenate y_train and df_train\n",
        "y_train = pd.read_csv(data_dir  / \"train_output.csv\")\n",
        "df_train = df_train.merge(y_train, on=\"Sample ID\")\n",
        "\n",
        "print(f\"Training data dimensions: {df_train.shape}\")  # (344, 4)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv8nKM7YtHj8"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6PqHcGotHj8"
      },
      "source": [
        "We now load the features matrices $\\mathbf{K_s} \\in \\mathbb{R}^{(1000,\\,2048)}$ for $s=1,...,344$ and perform slide-level averaging. This operation should take at most 5 minutes on your laptop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:52.890700Z",
          "start_time": "2022-10-24T07:22:50.480795Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWhTx2mstHj9",
        "outputId": "476fdae9-13f8-42cb-c0aa-1a45b3b16423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344/344 [00:02<00:00, 165.32it/s]\n",
            "100%|██████████| 149/149 [00:07<00:00, 20.91it/s]\n"
          ]
        }
      ],
      "source": [
        "X_train_mean = []\n",
        "y_train = []\n",
        "centers_train = []\n",
        "patients_train = []\n",
        "\n",
        "for sample, label, center, patient in tqdm(\n",
        "    df_train[[\"Sample ID\", \"Target\", \"Center ID\", \"Patient ID\"]].values\n",
        "):\n",
        "    # load the coordinates and features (1000, 3+2048)\n",
        "    _features = np.load(train_features_dir / sample)\n",
        "    # get coordinates (zoom level, tile x-coord on the slide, tile y-coord on the slide)\n",
        "    # and the MoCo V2 features\n",
        "    coordinates, features = _features[:, :3], _features[:, 3:]  # Ks\n",
        "    # slide-level averaging\n",
        "    X_train_mean.append(np.mean(features, axis=0))\n",
        "    y_train.append(label)\n",
        "    centers_train.append(center)\n",
        "    patients_train.append(patient)\n",
        "\n",
        "# convert to numpy arrays\n",
        "X_train_mean = np.array(X_train_mean)\n",
        "y_train = np.array(y_train)\n",
        "centers_train = np.array(centers_train)\n",
        "patients_train = np.array(patients_train)\n",
        "\n",
        "\n",
        "X_test_mean = []\n",
        "centers_test = []\n",
        "\n",
        "# load the data from `df_test` (~ 1 minute)\n",
        "for sample, center in tqdm(df_test[[\"Sample ID\", \"Center ID\"]].values):\n",
        "    _features = np.load(test_features_dir / sample)\n",
        "    coordinates, features = _features[:, :3], _features[:, 3:]\n",
        "    X_test_mean.append(np.mean(features, axis=0))\n",
        "    centers_test.append(center)\n",
        "\n",
        "X_test_mean = np.array(X_test_mean)\n",
        "centers_test = np.array(centers_test)\n",
        "\n",
        "X_mean = np.concatenate([X_train_mean, X_test_mean])\n",
        "centers = np.concatenate([centers_train, centers_test])\n",
        "\n",
        "preprocessing = {}\n",
        "for center in np.unique(centers):\n",
        "  mean = np.mean(X_mean[centers==center], axis=0)\n",
        "  std = np.std(X_mean[centers==center], axis=0)\n",
        "  preprocessing[center] = {'mean': mean, 'std': std}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rm2f9p8tHj9"
      },
      "source": [
        "## Multilayer perceptron with a max over an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9vy_IQ1JtHj-"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.functional import F\n",
        "\n",
        "class Perceptron(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Perceptron, self).__init__()\n",
        "        \n",
        "\n",
        "        self.attention_weight = nn.Sequential(\n",
        "            nn.Linear(2048,16),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(16,1)\n",
        "        )\n",
        "        self.gate_weight = nn.Sequential(\n",
        "            nn.Linear(2048, 16),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(16,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.hidden = nn.Linear(16, 1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x #BxNx2048\n",
        "\n",
        "        f = self.attention_weight(x)\n",
        "        g = self.gate_weight(x)\n",
        "\n",
        "        A = F.softmax(f*g, dim=1) #BxNx1\n",
        "        \n",
        "        x = torch.sum(x*A, axis=1)\n",
        "\n",
        "        output = self.classifier(x)\n",
        "        \n",
        "        return output.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N50Ej0oVtHj-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df, features_dir, test = False):\n",
        "        self.df = df\n",
        "        self.features_dir = features_dir\n",
        "        self.test = test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.test:\n",
        "            sample, center = self.df.iloc[idx][[\"Sample ID\", \"Center ID\"]]\n",
        "        else:\n",
        "            sample, label, center = self.df.iloc[idx][[\"Sample ID\", \"Target\", \"Center ID\"]]\n",
        "            \n",
        "        # load the coordinates and features (1000, 3+2048)\n",
        "        _features = np.load(self.features_dir / sample)\n",
        "        # get coordinates (zoom level, tile x-coord on the slide, tile y-coord on the slide)\n",
        "        # and the MoCo V2 features\n",
        "        coordinates, features = _features[:, :3], _features[:, 3:]  # Ks\n",
        "        features = (features - preprocessing[center]['mean']) / preprocessing[center]['std']\n",
        "\n",
        "        if self.test:\n",
        "            return {'x': features}\n",
        "        return {'x':features, 'y':label}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fnSank0stHj_"
      },
      "outputs": [],
      "source": [
        "N_split = 344//5 * 4\n",
        "train_dataset = MyDataset(df=df_train.iloc[:N_split], features_dir=train_features_dir)\n",
        "val_dataset = MyDataset(df=df_train.iloc[N_split:], features_dir=train_features_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lf2crsNxtHj_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "loader = DataLoader(dataset=train_dataset, batch_size=35)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=35)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DE5Mo1zgtHkA"
      },
      "outputs": [],
      "source": [
        "from torch.nn import BCELoss\n",
        "from torch.optim import Adam\n",
        "\n",
        "model = Perceptron().to(device)\n",
        "criterion = BCELoss().to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.00005, weight_decay=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, tolerance=5, min_delta=0):\n",
        "\n",
        "        self.tolerance = tolerance\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "        self.last_val = 1e12\n",
        "\n",
        "    def __call__(self, train_loss, validation_loss):\n",
        "        if validation_loss >= self.last_val:\n",
        "            self.counter +=1\n",
        "            if self.counter >= self.tolerance:  \n",
        "                self.early_stop = True\n",
        "        else:\n",
        "          self.last_val = validation_loss\n",
        "          self.counter = 0\n",
        "\n",
        "class SaveBestModel:\n",
        "    \"\"\"\n",
        "    Class to save the best model while training. If the current epoch's \n",
        "    validation loss is less than the previous least less, then save the\n",
        "    model state.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, best_valid_loss=float('inf'), save_path='outputs/best_model.pth'\n",
        "    ):\n",
        "        self.best_valid_loss = best_valid_loss\n",
        "        self.save_path=save_path\n",
        "        \n",
        "    def __call__(\n",
        "        self, current_valid_loss, \n",
        "        epoch, model, optimizer, criterion\n",
        "    ):\n",
        "        if current_valid_loss < self.best_valid_loss:\n",
        "            self.best_valid_loss = current_valid_loss\n",
        "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
        "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
        "            torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, self.save_path)"
      ],
      "metadata": {
        "id": "4r1XPnf96geY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "t-_eezKLtHkA"
      },
      "outputs": [],
      "source": [
        "def train(loader, sigma = 1e-2):\n",
        "    model.train()\n",
        "    mean_loss = 0\n",
        "    for i, val in enumerate(loader):\n",
        "        labels = val['y'].to(device)\n",
        "        x = val['x'].to(device)\n",
        "        noise = sigma * torch.randn_like(x)\n",
        "\n",
        "        x = x + noise\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "\n",
        "        \n",
        "        loss = criterion(output, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        mean_loss = 1/(i+1) * loss + i / (i+1) * mean_loss\n",
        "    return mean_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "b-Pi_55RtHkA"
      },
      "outputs": [],
      "source": [
        "def train_fold(model, optimizer, criterion, loader, val_loader=[], n_epoch = 10, verbose=1, sigma=1e-2, model_name='model'):\n",
        "    early_stopping = EarlyStopping(tolerance = 3, min_delta=0.005)\n",
        "    #save_best_model = SaveBestModel(save_path='./outputs_'+model_name+'_best_weights.pth')\n",
        "    \n",
        "    for epoch in range(n_epoch):\n",
        "        loss = train(loader, sigma=sigma)\n",
        "\n",
        "        val_loss = 0\n",
        "        for i, val in enumerate(val_loader):\n",
        "            model.eval()\n",
        "\n",
        "            labels = val['y'].to(device)\n",
        "            x = val['x'].to(device)\n",
        "            \n",
        "            output = model(x)\n",
        "            \n",
        "            v_loss = criterion(output, labels.float())\n",
        "\n",
        "            val_loss = 1/(i+1) * (v_loss) + i / (i+1) * val_loss\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch} - loss {loss:.4f} - val loss {val_loss:.4f}\")\n",
        "        \n",
        "        #best model\n",
        "        #save_best_model(val_loss, epoch=epoch, model=model, optimizer=optimizer, criterion=criterion)\n",
        "        # early stopping\n",
        "        early_stopping(loss, val_loss)\n",
        "        if early_stopping.early_stop:\n",
        "          torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, './outputs_'+model_name+'_best_weights.pth')\n",
        "          print(\"We are at epoch:\", epoch)\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWHCeuD6tHkB",
        "outputId": "c4bb58fd-4125-4d98-be25-a19974578c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - loss 0.7098 - val loss 0.6051\n",
            "Epoch 1 - loss 0.6908 - val loss 0.5920\n",
            "Epoch 2 - loss 0.6757 - val loss 0.5806\n",
            "Epoch 3 - loss 0.6621 - val loss 0.5707\n",
            "Epoch 4 - loss 0.6495 - val loss 0.5618\n",
            "Epoch 5 - loss 0.6376 - val loss 0.5537\n",
            "Epoch 6 - loss 0.6263 - val loss 0.5463\n",
            "Epoch 7 - loss 0.6155 - val loss 0.5395\n",
            "Epoch 8 - loss 0.6051 - val loss 0.5332\n",
            "Epoch 9 - loss 0.5952 - val loss 0.5274\n",
            "Epoch 10 - loss 0.5857 - val loss 0.5221\n",
            "Epoch 11 - loss 0.5767 - val loss 0.5172\n",
            "Epoch 12 - loss 0.5682 - val loss 0.5128\n",
            "Epoch 13 - loss 0.5602 - val loss 0.5088\n",
            "Epoch 14 - loss 0.5526 - val loss 0.5052\n"
          ]
        }
      ],
      "source": [
        "train_fold(model, optimizer, criterion, loader, val_loader, n_epoch=300, verbose=1, sigma = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the best model checkpoint\n",
        "best_model_cp = torch.load('outputs_model_best_weights.pth')\n",
        "best_model_epoch = best_model_cp['epoch']\n",
        "print(f\"Best model was saved at {best_model_epoch} epochs\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVoKhXab_Cw-",
        "outputId": "3b5b61d1-49fe-4853-b4d5-cab78f93e1c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model was saved at 28 epochs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_cp = torch.load('outputs_model_best_weights.pth')\n",
        "model.load_state_dict(best_model_cp['model_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niI4xrE8_l1F",
        "outputId": "3c3a21ac-83f6-4aca-8461-44c14eb6e065"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwyob_intHkB",
        "outputId": "4ba2d26e-cc67-464e-9af2-82126c15d2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7404761904761905\n"
          ]
        }
      ],
      "source": [
        "y_trues = []\n",
        "preds = []\n",
        "for val in val_loader:\n",
        "    model.eval()\n",
        "    y_true = val['y'].detach().numpy().tolist()\n",
        "    x = val['x'].to(device)\n",
        "\n",
        "    pred = model(x).detach().cpu().numpy().tolist()\n",
        "    y_trues.extend(y_true)\n",
        "    preds.extend(pred)\n",
        "\n",
        "auc = roc_auc_score(y_trues, preds)\n",
        "\n",
        "print(auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t4kjgMFtHkC"
      },
      "source": [
        "## 5-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:52.905566Z",
          "start_time": "2022-10-24T07:22:52.893435Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th4Cs0iqtHkC",
        "outputId": "befcc55f-0929-459e-eee6-74b4722e56bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set specifications\n",
            "---------------------------\n",
            "344 unique samples\n",
            "305 unique patients\n",
            "3 unique centers\n"
          ]
        }
      ],
      "source": [
        "# /!\\ we perform splits at the patient level so that all samples from the same patient\n",
        "# are found in the same split\n",
        "\n",
        "patients_unique = np.unique(patients_train)\n",
        "y_unique = np.array(\n",
        "    [np.mean(y_train[patients_train == p]) for p in patients_unique]\n",
        ")\n",
        "centers_unique = np.array(\n",
        "    [centers_train[patients_train == p][0] for p in patients_unique]\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Training set specifications\\n\"\n",
        "    \"---------------------------\\n\"\n",
        "    f\"{len(df_train)} unique samples\\n\"\n",
        "    f\"{len(patients_unique)} unique patients\\n\"\n",
        "    f\"{len(np.unique(centers_unique))} unique centers\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:54.077640Z",
          "start_time": "2022-10-24T07:22:52.907331Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BWyq3AqtHkC",
        "outputId": "c5729936-61a7-4b97-a1d2-15531c25be99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are at epoch: 10\n",
            "AUC on split 0 fold 0: 0.560\n",
            "We are at epoch: 16\n",
            "AUC on split 0 fold 1: 0.768\n",
            "We are at epoch: 30\n",
            "AUC on split 0 fold 2: 0.698\n",
            "We are at epoch: 6\n",
            "AUC on split 0 fold 3: 0.675\n",
            "We are at epoch: 17\n",
            "AUC on split 0 fold 4: 0.614\n",
            "----------------------------\n",
            "We are at epoch: 3\n",
            "AUC on split 1 fold 0: 0.516\n",
            "We are at epoch: 21\n",
            "AUC on split 1 fold 1: 0.742\n",
            "We are at epoch: 12\n",
            "AUC on split 1 fold 2: 0.645\n",
            "We are at epoch: 3\n",
            "AUC on split 1 fold 3: 0.469\n",
            "We are at epoch: 12\n",
            "AUC on split 1 fold 4: 0.561\n",
            "----------------------------\n",
            "We are at epoch: 8\n",
            "AUC on split 2 fold 0: 0.568\n",
            "We are at epoch: 18\n",
            "AUC on split 2 fold 1: 0.752\n",
            "We are at epoch: 24\n",
            "AUC on split 2 fold 2: 0.653\n",
            "We are at epoch: 7\n",
            "AUC on split 2 fold 3: 0.594\n",
            "We are at epoch: 8\n",
            "AUC on split 2 fold 4: 0.520\n",
            "----------------------------\n",
            "We are at epoch: 29\n",
            "AUC on split 3 fold 0: 0.733\n",
            "We are at epoch: 3\n",
            "AUC on split 3 fold 1: 0.490\n",
            "We are at epoch: 53\n",
            "AUC on split 3 fold 2: 0.775\n",
            "We are at epoch: 9\n",
            "AUC on split 3 fold 3: 0.563\n",
            "We are at epoch: 16\n",
            "AUC on split 3 fold 4: 0.658\n",
            "----------------------------\n",
            "We are at epoch: 3\n",
            "AUC on split 4 fold 0: 0.665\n",
            "We are at epoch: 17\n",
            "AUC on split 4 fold 1: 0.637\n",
            "We are at epoch: 12\n",
            "AUC on split 4 fold 2: 0.681\n",
            "We are at epoch: 23\n",
            "AUC on split 4 fold 3: 0.622\n",
            "We are at epoch: 20\n",
            "AUC on split 4 fold 4: 0.583\n",
            "----------------------------\n",
            "5-fold cross-validated AUC averaged over 5 repeats: 0.630 (0.085)\n"
          ]
        }
      ],
      "source": [
        "aucs = []\n",
        "models = []\n",
        "# 5-fold CV is repeated 5 times with different random states\n",
        "for k in range(5):\n",
        "    kfold = StratifiedKFold(5, shuffle=True, random_state=k)\n",
        "    fold = 0\n",
        "    # split is performed at the patient-level\n",
        "    for train_idx_, val_idx_ in kfold.split(patients_unique, y_unique):\n",
        "        # retrieve the indexes of the samples corresponding to the\n",
        "        # patients in `train_idx_` and `test_idx_`\n",
        "        train_idx = np.arange(len(df_train))[\n",
        "            pd.Series(patients_train).isin(patients_unique[train_idx_])\n",
        "        ]\n",
        "        val_idx = np.arange(len(df_train))[\n",
        "            pd.Series(patients_train).isin(patients_unique[val_idx_])\n",
        "        ]\n",
        "        # set the training and validation folds\n",
        "        df_fold_train = df_train.iloc[train_idx]\n",
        "        data_fold_train = MyDataset(df_fold_train, train_features_dir)\n",
        "        loader_fold_train = DataLoader(data_fold_train, batch_size=35, shuffle=True)\n",
        "\n",
        "        df_fold_val = df_train.iloc[val_idx]\n",
        "        data_fold_val = MyDataset(df_fold_val, train_features_dir)\n",
        "        loader_fold_val = DataLoader(data_fold_val, batch_size=35, shuffle=True)\n",
        "        \n",
        "        # instantiate the model\n",
        "        model = Perceptron().to(device)\n",
        "        criterion = BCELoss().to(device)\n",
        "        optimizer = Adam(model.parameters(), lr=0.00005, weight_decay=1)\n",
        "        \n",
        "        model_name = f'MLP_{k}_{fold}'\n",
        "        train_fold(model, optimizer, criterion, loader_fold_train, val_loader=loader_fold_val, verbose=0, n_epoch=300, sigma = 0.0001, model_name=model_name)\n",
        "\n",
        "        best_model_cp = torch.load('outputs_'+ model_name + '_best_weights.pth')\n",
        "        model.load_state_dict(best_model_cp['model_state_dict'])\n",
        "\n",
        "        # get the predictions (1-d probability)\n",
        "        y_trues = []\n",
        "        preds = []\n",
        "        for val in loader_fold_val:\n",
        "            model.eval()\n",
        "            y_true = val['y'].detach().cpu().numpy().tolist()\n",
        "            x = val['x'].to(device)\n",
        "\n",
        "            pred = model(x).detach().cpu().numpy().tolist()\n",
        "            y_trues.extend(y_true)\n",
        "            preds.extend(pred)\n",
        "\n",
        "        auc = roc_auc_score(y_trues, preds)\n",
        "\n",
        "        print(f\"AUC on split {k} fold {fold}: {auc:.3f}\")\n",
        "        aucs.append(auc)\n",
        "        # add the logistic regression to the list of classifiers\n",
        "        models.append(model_name)\n",
        "        fold += 1\n",
        "    print(\"----------------------------\")\n",
        "print(\n",
        "    f\"5-fold cross-validated AUC averaged over {k+1} repeats: \"\n",
        "    f\"{np.mean(aucs):.3f} ({np.std(aucs):.3f})\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5QBiOMltHkD"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXszLbxWtHkD"
      },
      "source": [
        "Now we evaluate the previous models trained through cross-validation so that to produce a submission file that can directly be uploaded on the data challenge platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WLw6VpwtHkD"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "id": "T97MdixbxVfU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "5e7d9127-3028-4a44-ff1c-056b03ba72a5"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sample ID Patient ID Center ID\n",
              "0    ID_003.npy      P_003       C_3\n",
              "1    ID_004.npy      P_004       C_4\n",
              "2    ID_008.npy      P_008       C_4\n",
              "3    ID_009.npy      P_009       C_4\n",
              "4    ID_010.npy      P_010       C_3\n",
              "..          ...        ...       ...\n",
              "144  ID_482.npy      P_445       C_3\n",
              "145  ID_487.npy      P_449       C_3\n",
              "146  ID_488.npy      P_450       C_4\n",
              "147  ID_492.npy      P_453       C_4\n",
              "148  ID_493.npy      P_454       C_3\n",
              "\n",
              "[149 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8218cac5-1fcb-4da6-b026-df7c50f057b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample ID</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Center ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_003.npy</td>\n",
              "      <td>P_003</td>\n",
              "      <td>C_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_004.npy</td>\n",
              "      <td>P_004</td>\n",
              "      <td>C_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_008.npy</td>\n",
              "      <td>P_008</td>\n",
              "      <td>C_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_009.npy</td>\n",
              "      <td>P_009</td>\n",
              "      <td>C_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_010.npy</td>\n",
              "      <td>P_010</td>\n",
              "      <td>C_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>ID_482.npy</td>\n",
              "      <td>P_445</td>\n",
              "      <td>C_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>ID_487.npy</td>\n",
              "      <td>P_449</td>\n",
              "      <td>C_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>ID_488.npy</td>\n",
              "      <td>P_450</td>\n",
              "      <td>C_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>ID_492.npy</td>\n",
              "      <td>P_453</td>\n",
              "      <td>C_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>ID_493.npy</td>\n",
              "      <td>P_454</td>\n",
              "      <td>C_3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8218cac5-1fcb-4da6-b026-df7c50f057b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8218cac5-1fcb-4da6-b026-df7c50f057b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8218cac5-1fcb-4da6-b026-df7c50f057b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:54.987815Z",
          "start_time": "2022-10-24T07:22:54.079916Z"
        },
        "id": "SZPmMi50tHkD"
      },
      "outputs": [],
      "source": [
        "dataset_test = MyDataset(df_test, test_features_dir, test=True)\n",
        "\n",
        "loader_test = DataLoader(dataset_test, batch_size=20, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test[1]"
      ],
      "metadata": {
        "id": "Xi_VmNkyw44D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4df0bb-45c3-4d37-dc10-f0eadb6b2dd7"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': array([[-2.183074  , -0.96264654,  2.2047734 , ..., -0.33695048,\n",
              "         -1.0075642 ,  1.939822  ],\n",
              "        [ 3.0640392 , -0.96264654, -0.9845473 , ...,  1.0388631 ,\n",
              "          2.830239  , -0.451777  ],\n",
              "        [-2.7147825 , -0.96264654,  1.5508125 , ..., -1.5487558 ,\n",
              "         -1.0016519 , -0.01437623],\n",
              "        ...,\n",
              "        [-0.90114534, -0.96264654, -0.8540166 , ...,  6.3820148 ,\n",
              "         -0.73208576, -1.0505995 ],\n",
              "        [-1.5130209 , -0.96264654, -0.99871415, ..., -1.5487558 ,\n",
              "         -1.0075642 , -1.0505995 ],\n",
              "        [ 3.3647478 , -0.4947247 , -0.26550445, ..., -1.1927309 ,\n",
              "          0.951436  , -0.57781005]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T08:17:35.617554Z",
          "start_time": "2022-10-20T08:17:35.603562Z"
        },
        "id": "O9GbDCC4tHkE"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:55.043255Z",
          "start_time": "2022-10-24T07:22:54.989274Z"
        },
        "id": "6i0le2B2tHkE"
      },
      "outputs": [],
      "source": [
        "preds_test = 0\n",
        "\n",
        "\n",
        "# loop over the classifiers\n",
        "for model_name in models:\n",
        "    \n",
        "    preds = []\n",
        "    for val in loader_test:\n",
        "        model = Perceptron().to(device)\n",
        "        best_model_cp = torch.load('outputs_'+ model_name + '_best_weights.pth')\n",
        "        model.load_state_dict(best_model_cp['model_state_dict'])\n",
        "        model.eval()\n",
        "        x = val['x'].to(device)\n",
        "\n",
        "        pred = model(x).detach().cpu().numpy().tolist()\n",
        "        preds.extend(pred)\n",
        "\n",
        "    preds = np.array(preds)\n",
        "    preds_test += preds\n",
        "# and take the average (ensembling technique)\n",
        "preds_test = preds_test / len(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Ax63WHtHkE"
      },
      "source": [
        "## Saving predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:55.098571Z",
          "start_time": "2022-10-24T07:22:55.044975Z"
        },
        "id": "of-SNwlhtHkF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4526298f-fb1c-4168-c6f4-dde81f73dcaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sample ID    Target\n",
              "0  ID_003.npy  0.459709\n",
              "1  ID_004.npy  0.483883\n",
              "2  ID_008.npy  0.425405\n",
              "3  ID_009.npy  0.327352\n",
              "4  ID_010.npy  0.298447"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6342465-ebf1-452b-9be6-6177711ce113\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample ID</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_003.npy</td>\n",
              "      <td>0.459709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_004.npy</td>\n",
              "      <td>0.483883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_008.npy</td>\n",
              "      <td>0.425405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_009.npy</td>\n",
              "      <td>0.327352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_010.npy</td>\n",
              "      <td>0.298447</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6342465-ebf1-452b-9be6-6177711ce113')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6342465-ebf1-452b-9be6-6177711ce113 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6342465-ebf1-452b-9be6-6177711ce113');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "submission = pd.DataFrame(\n",
        "    {\"Sample ID\": df_test[\"Sample ID\"].values, \"Target\": preds_test}\n",
        ").sort_values(\n",
        "    \"Sample ID\"\n",
        ")  # extra step to sort the sample IDs\n",
        "\n",
        "# sanity checks\n",
        "assert all(submission[\"Target\"].between(0, 1)), \"`Target` values must be in [0, 1]\"\n",
        "assert submission.shape == (149, 2), \"Your submission file must be of shape (149, 2)\"\n",
        "assert list(submission.columns) == [\n",
        "    \"Sample ID\",\n",
        "    \"Target\",\n",
        "], \"Your submission file must have columns `Sample ID` and `Target`\"\n",
        "\n",
        "# save the submission as a csv file\n",
        "submission.to_csv(data_dir / \"benchmark_test_output_MLP_scaled_data_2eme_test.csv\", index=None)\n",
        "\n",
        "%cp ./benchmark_test_output_MLP_scaled_data_2eme_test.csv /content/drive/MyDrive/challenge_ens_2023_small/benchmark_test_output_MLP_scaled_data_2eme_test.csv\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp ./benchmark_test_output.csv content/drive/MyDrive/challenge_ens_2023_small/benchmark_test_output.csv"
      ],
      "metadata": {
        "id": "cWfRhnzAFp0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40fc2bd8-a546-4cfa-8e5b-7963d13945de"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat './benchmark_test_output.csv': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBZDlA_QtHkF"
      },
      "source": [
        "# Dealing with images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4N09eRLtHkF"
      },
      "source": [
        "The following code aims to load and manipulate the images provided as part of  this challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo0uzTl-tHkG"
      },
      "source": [
        "## Scanning images paths on disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhkZ3RDftHkG"
      },
      "source": [
        "This operation can take up to 5 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:00.263580Z",
          "start_time": "2022-10-24T07:22:55.100342Z"
        },
        "id": "nRB1V26ktHkG"
      },
      "outputs": [],
      "source": [
        "train_images_dir = data_dir / \"train_input\" / \"images\"\n",
        "train_images_files = list(train_images_dir.rglob(\"*.jpg\"))\n",
        "\n",
        "test_images_dir = data_dir / \"test_input\" / \"images\"\n",
        "test_images_files = list(test_images_dir.rglob(\"*.jpg\"))\n",
        "\n",
        "print(\n",
        "    f\"Number of images\\n\"\n",
        "    \"-----------------\\n\"\n",
        "    f\"Train: {len(train_images_files)}\\n\" # 344 x 1000 = 344,000 tiles\n",
        "    f\"Test: {len(test_images_files)}\\n\"  # 149 x 1000 = 149,000 tiles\n",
        "    f\"Total: {len(train_images_files) + len(test_images_files)}\\n\"  # 493 x 1000 = 493,000 tiles\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T10:16:48.078600Z",
          "start_time": "2022-10-20T10:16:47.948127Z"
        },
        "id": "nHmmEQx4tHkH"
      },
      "source": [
        "## Reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vULU7SitHkH"
      },
      "source": [
        "Now we can load some of the `.jpg` images for a given sample, say `ID_001`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:00.381225Z",
          "start_time": "2022-10-24T07:23:00.267047Z"
        },
        "id": "rLyRuEe8tHkI"
      },
      "outputs": [],
      "source": [
        "ID_001_tiles = [p for p in train_images_files if 'ID_001' in p.name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:01.973155Z",
          "start_time": "2022-10-24T07:23:00.382760Z"
        },
        "id": "P4E6K-mMtHkI"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(5, 5)\n",
        "fig.set_size_inches(12, 12)\n",
        "\n",
        "for i, img_file in enumerate(ID_001_tiles[:25]):\n",
        "    # get the metadata from the file path\n",
        "    _, metadata = str(img_file).split(\"tile_\")\n",
        "    id_tile, level, x, y = metadata[:-4].split(\"_\")\n",
        "    img = plt.imread(img_file)\n",
        "    ax = axes[i//5, i%5]\n",
        "    ax.imshow(img)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_title(f\"Tile {id_tile} ({x}, {y})\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iEVWY8otHkI"
      },
      "source": [
        "## Mapping with features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM6yjhS1tHkJ"
      },
      "source": [
        "Note that the coordinates in the features matrices and tiles number are aligned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:01.984327Z",
          "start_time": "2022-10-24T07:23:01.974933Z"
        },
        "id": "iAoTnjxLtHkJ"
      },
      "outputs": [],
      "source": [
        "sample = \"ID_001.npy\"\n",
        "_features = np.load(train_features_dir / sample)\n",
        "coordinates, features = _features[:, :3], _features[:, 3:]\n",
        "print(\"xy features coordinates\")\n",
        "coordinates[:10, 1:].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:01.990342Z",
          "start_time": "2022-10-24T07:23:01.985926Z"
        },
        "id": "IrAp_y9dtHkK"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    \"Tiles numbering and features coordinates\\n\"\n",
        ")\n",
        "[tile.name for tile in ID_001_tiles[:10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP_5IxWNtHkK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHgk7DOxtHkK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}