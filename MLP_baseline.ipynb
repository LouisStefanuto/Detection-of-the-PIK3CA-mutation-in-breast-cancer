{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkOUh2HptHjx"
      },
      "source": [
        "Before starting, you will need to install some packages to reproduce the baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:49.282534Z",
          "start_time": "2022-10-24T07:22:35.359325Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYHxK0njtHjz",
        "outputId": "c87a32f9-e254-4f1d-9ca0-7384100ef3d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:50.448803Z",
          "start_time": "2022-10-24T07:22:49.285830Z"
        },
        "id": "L4-Z4UoCtHj0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxW2WuijtHj2",
        "outputId": "cdb97819-604e-46ad-c407-9518d051cdd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/challenge_data_ens_small/'\n",
            "/content\n",
            "Archive:  /content/drive/MyDrive/challenge_ens_2023_small/moco_features.zip\n",
            "replace /content/test_input/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# import data\n",
        "PATH_COLAB = '/content/drive/MyDrive/challenge_ens_2023_small/moco_features.zip'\n",
        "PATH_DEVICE = '..'\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    logging.info('Working on Colab.')\n",
        "    \n",
        "    # connect your drive to the session\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    %cd /content/drive/MyDrive/challenge_data_ens_small/\n",
        "\n",
        "    # unzip data into the colab session\n",
        "    ! unzip $PATH_COLAB -d /content\n",
        "    logging.info('Data unziped in your Drive.')\n",
        "\n",
        "    %cd /content\n",
        "\n",
        "    %cp -R drive/MyDrive/challenge_ens_2023_small/supplementary_data/ .\n",
        "    %cp drive/MyDrive/challenge_ens_2023_small/train_output.csv .\n",
        "\n",
        "\n",
        "except:\n",
        "    logging.info('Working on your device.')\n",
        "    \n",
        "    data_exists = os.path.exists(PATH_DEVICE + '/train_input') and os.path.exists(PATH_DEVICE + '/test_input') and os.path.exists(PATH_DEVICE + '/train_output.csv')\n",
        "    \n",
        "    if data_exists:\n",
        "        logging.info(f\"Dataset found on device at : '{PATH_DEVICE}.'\") \n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Data folder not found at '{PATH_DEVICE}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwNiwkdUtHj4",
        "outputId": "1b052dd2-9360-415a-d5b1-2143f9064a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g561bAvWtHj4"
      },
      "source": [
        "# Data architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T15:29:41.479814Z",
          "start_time": "2022-10-20T15:29:41.472869Z"
        },
        "id": "HTGcDg_OtHj5"
      },
      "source": [
        "After downloading or unzipping the downloaded files, your data tree must have the following architecture in order to properly run the notebook:\n",
        "```\n",
        "your_data_dir/\n",
        "├── train_output.csv\n",
        "├── train_input/\n",
        "│   ├── images/\n",
        "│       ├── ID_001/\n",
        "│           ├── ID_001_tile_000_17_170_43.jpg\n",
        "...\n",
        "│   └── moco_features/\n",
        "│       ├── ID_001.npy\n",
        "...\n",
        "├── test_input/\n",
        "│   ├── images/\n",
        "│       ├── ID_003/\n",
        "│           ├── ID_003_tile_000_16_114_93.jpg\n",
        "...\n",
        "│   └── moco_features/\n",
        "│       ├── ID_003.npy\n",
        "...\n",
        "├── supplementary_data/\n",
        "│   ├── baseline.ipynb\n",
        "│   ├── test_metadata.csv\n",
        "│   └── train_metadata.csv\n",
        "```\n",
        "\n",
        "For instance, `your_data_dir = /storage/DATA_CHALLENGE_ENS_2022/`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYiFEHvttHj6"
      },
      "source": [
        "This notebook aims to reproduce the baseline method on this challenge called `MeanPool`. This method consists in a logistic regression learnt on top of tile-level MoCo V2 features averaged over the slides.\n",
        "\n",
        "For a given slide $s$ with $N_s=1000$ tiles and corresponding MoCo V2 features $\\mathbf{K_s} \\in \\mathbb{R}^{(1000,\\,2048)}$, a slide-level average is performed over the tile axis.\n",
        "\n",
        "For $j=1,...,2048$:\n",
        "\n",
        "$$\\overline{\\mathbf{k_s}}(j) = \\frac{1}{N_s} \\sum_{i=1}^{N_s} \\mathbf{K_s}(i, j) $$\n",
        "\n",
        "Thus, the training input data for MeanPool consists of $S_{\\text{train}}=344$ mean feature vectors $\\mathbf{k_s}$, $s=1,...,S_{\\text{train}}$, where $S_{\\text{train}}$ denotes the number of training samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T09:25:58.896288Z",
          "start_time": "2022-10-20T09:25:58.161711Z"
        },
        "id": "HWlYU146tHj6"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:50.479040Z",
          "start_time": "2022-10-24T07:22:50.450662Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "nqplkW7RtHj7",
        "outputId": "12b6b4f3-a19a-4504-dc49-9a8ea07c88dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data dimensions: (344, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sample ID Patient ID Center ID  Target\n",
              "0  ID_001.npy      P_001       C_1       0\n",
              "1  ID_002.npy      P_002       C_2       1\n",
              "2  ID_005.npy      P_005       C_5       0\n",
              "3  ID_006.npy      P_006       C_5       0\n",
              "4  ID_007.npy      P_007       C_2       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a388295b-06ad-41bf-ac52-0157c25980c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample ID</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Center ID</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_001.npy</td>\n",
              "      <td>P_001</td>\n",
              "      <td>C_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_002.npy</td>\n",
              "      <td>P_002</td>\n",
              "      <td>C_2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_005.npy</td>\n",
              "      <td>P_005</td>\n",
              "      <td>C_5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_006.npy</td>\n",
              "      <td>P_006</td>\n",
              "      <td>C_5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_007.npy</td>\n",
              "      <td>P_007</td>\n",
              "      <td>C_2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a388295b-06ad-41bf-ac52-0157c25980c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a388295b-06ad-41bf-ac52-0157c25980c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a388295b-06ad-41bf-ac52-0157c25980c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# put your own path to the data root directory (see example in `Data architecture` section)\n",
        "data_dir = Path(\"./\")\n",
        "\n",
        "# load the training and testing data sets\n",
        "train_features_dir = data_dir / \"train_input\" / \"moco_features\"\n",
        "test_features_dir = data_dir / \"test_input\" / \"moco_features\"\n",
        "df_train = pd.read_csv(data_dir  / \"supplementary_data\" / \"train_metadata.csv\")\n",
        "df_test = pd.read_csv(data_dir  / \"supplementary_data\" / \"test_metadata.csv\")\n",
        "\n",
        "# concatenate y_train and df_train\n",
        "y_train = pd.read_csv(data_dir  / \"train_output.csv\")\n",
        "df_train = df_train.merge(y_train, on=\"Sample ID\")\n",
        "\n",
        "print(f\"Training data dimensions: {df_train.shape}\")  # (344, 4)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv8nKM7YtHj8"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6PqHcGotHj8"
      },
      "source": [
        "We now load the features matrices $\\mathbf{K_s} \\in \\mathbb{R}^{(1000,\\,2048)}$ for $s=1,...,344$ and perform slide-level averaging. This operation should take at most 5 minutes on your laptop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:52.890700Z",
          "start_time": "2022-10-24T07:22:50.480795Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWhTx2mstHj9",
        "outputId": "e3eda834-fada-46e0-a07b-4988a0ba0d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344/344 [00:00<00:00, 545703.70it/s]\n"
          ]
        }
      ],
      "source": [
        "#size_train = 50 #len(df_train)\n",
        "#X_train = np.zeros((size_train, 1000, 2048))\n",
        "#y_train = np.zeros((size_train), dtype=int)\n",
        "centers_train = []\n",
        "patients_train = []\n",
        "\n",
        "for i, (sample, label, center, patient) in enumerate(tqdm(\n",
        "    df_train[[\"Sample ID\", \"Target\", \"Center ID\", \"Patient ID\"]].values\n",
        ")):\n",
        "    # load the coordinates and features (1000, 3+2048)\n",
        "    #_features = np.load(train_features_dir / sample)\n",
        "    # get coordinates (zoom level, tile x-coord on the slide, tile y-coord on the slide)\n",
        "    # and the MoCo V2 features\n",
        "    #coordinates, features = _features[:, :3], _features[:, 3:]  # Ks\n",
        "    # slide-level averaging\n",
        "    #X_train[i] = features\n",
        "    #y_train[i] = label\n",
        "    centers_train.append(center)\n",
        "    patients_train.append(patient)\n",
        "    \n",
        "\n",
        "# convert to numpy arrays\n",
        "#X_train = np.array(X_train)\n",
        "#y_train = np.array(y_train)\n",
        "centers_train = np.array(centers_train)\n",
        "patients_train = np.array(patients_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rm2f9p8tHj9"
      },
      "source": [
        "## Multilayer perceptron with a max over an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "9vy_IQ1JtHj-"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.functional import F\n",
        "\n",
        "class Perceptron(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Perceptron, self).__init__()\n",
        "        \n",
        "        self.input = nn.Linear(2048,512)\n",
        "\n",
        "        self.hidden = nn.Linear(512, 1)\n",
        "\n",
        "        self.output = nn.Linear(1000, 1)\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(p = 0.1)\n",
        "\n",
        "        self.relu = torch.nn.ReLU() # instead of Heaviside step fn  \n",
        "\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "        self.max = torch.nn  \n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.input(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        #x = self.dropout(x)\n",
        "        \n",
        "        x = self.hidden(x)\n",
        "        x = self.sigmoid(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.output(x)\n",
        "        #x = self.sigmoid(x)\n",
        "\n",
        "        \n",
        "        #x = torch.max(x, dim=1).values # instead of Heaviside step fn\n",
        "\n",
        "        #x = self.output(x)\n",
        "        output = self.sigmoid(x)\n",
        "        return output.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "N50Ej0oVtHj-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df, features_dir, test = False):\n",
        "        self.df = df\n",
        "        self.features_dir = features_dir\n",
        "        self.test = test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.test:\n",
        "            sample = self.df.iloc[idx][\"Sample ID\"]\n",
        "        else:\n",
        "            sample, label = self.df.iloc[idx][[\"Sample ID\", \"Target\"]]\n",
        "            \n",
        "        # load the coordinates and features (1000, 3+2048)\n",
        "        _features = np.load(self.features_dir / sample)\n",
        "        # get coordinates (zoom level, tile x-coord on the slide, tile y-coord on the slide)\n",
        "        # and the MoCo V2 features\n",
        "        coordinates, features = _features[:, :3], _features[:, 3:]  # Ks\n",
        "\n",
        "        if self.test:\n",
        "            return {'x': features}\n",
        "        return {'x':features, 'y':label}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "fnSank0stHj_"
      },
      "outputs": [],
      "source": [
        "N_split = 250\n",
        "train_dataset = MyDataset(df=df_train.iloc[:N_split], features_dir=train_features_dir)\n",
        "val_dataset = MyDataset(df=df_train.iloc[N_split:], features_dir=train_features_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "lf2crsNxtHj_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "loader = DataLoader(dataset=train_dataset, batch_size=32)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "DE5Mo1zgtHkA"
      },
      "outputs": [],
      "source": [
        "from torch.nn import BCELoss\n",
        "from torch.optim import Adam\n",
        "\n",
        "model = Perceptron().to(device)\n",
        "criterion = BCELoss().to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.01, weight_decay=1e-1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, tolerance=5, min_delta=0):\n",
        "\n",
        "        self.tolerance = tolerance\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, train_loss, validation_loss):\n",
        "        if (validation_loss - train_loss) > self.min_delta:\n",
        "            self.counter +=1\n",
        "            if self.counter >= self.tolerance:  \n",
        "                self.early_stop = True\n",
        "        elif train_loss > validation_loss:\n",
        "            self.counter = 0\n",
        "\n",
        "class SaveBestModel:\n",
        "    \"\"\"\n",
        "    Class to save the best model while training. If the current epoch's \n",
        "    validation loss is less than the previous least less, then save the\n",
        "    model state.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, best_valid_loss=float('inf'), save_path='outputs/best_model.pth'\n",
        "    ):\n",
        "        self.best_valid_loss = best_valid_loss\n",
        "        self.save_path=save_path\n",
        "        \n",
        "    def __call__(\n",
        "        self, current_valid_loss, \n",
        "        epoch, model, optimizer, criterion\n",
        "    ):\n",
        "        if current_valid_loss < self.best_valid_loss:\n",
        "            self.best_valid_loss = current_valid_loss\n",
        "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
        "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
        "            torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, self.save_path)"
      ],
      "metadata": {
        "id": "4r1XPnf96geY"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "t-_eezKLtHkA"
      },
      "outputs": [],
      "source": [
        "def train(loader, sigma = 1e-2):\n",
        "    model.train()\n",
        "    mean_loss = 0\n",
        "    for i, val in enumerate(loader):\n",
        "        labels = val['y'].to(device)\n",
        "        x = val['x'].to(device)\n",
        "        noise = sigma * torch.randn_like(x)\n",
        "\n",
        "        x = x + noise\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "\n",
        "        \n",
        "        loss = criterion(output, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        mean_loss = 1/(i+1) * (loss - mean_loss) + i / (i+1) * mean_loss\n",
        "    return mean_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "b-Pi_55RtHkA"
      },
      "outputs": [],
      "source": [
        "def train_fold(model, optimizer, criterion, loader, val_loader=[], n_epoch = 10, verbose=1, sigma=1e-2, model_name='model'):\n",
        "    early_stopping = EarlyStopping(tolerance = 5, min_delta=0.005)\n",
        "    save_best_model = SaveBestModel(save_path='./outputs_'+model_name+'_best_weights.pth')\n",
        "    \n",
        "    for epoch in range(n_epoch):\n",
        "        loss = train(loader, sigma=sigma)\n",
        "\n",
        "        val_loss = 0\n",
        "        for i, val in enumerate(val_loader):\n",
        "            model.eval()\n",
        "\n",
        "            labels = val['y'].to(device)\n",
        "            x = val['x'].to(device)\n",
        "            \n",
        "            output = model(x)\n",
        "            \n",
        "            v_loss = criterion(output, labels.float())\n",
        "\n",
        "            val_loss = 1/(i+1) * (v_loss - val_loss) + i / (i+1) * val_loss\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch} - loss {loss:.4f} - val loss {val_loss:.4f}\")\n",
        "        \n",
        "        #best model\n",
        "        save_best_model(val_loss, epoch=epoch, model=model, optimizer=optimizer, criterion=criterion)\n",
        "        # early stopping\n",
        "        early_stopping(loss, val_loss)\n",
        "        if early_stopping.early_stop:\n",
        "          print(\"We are at epoch:\", epoch)\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWHCeuD6tHkB",
        "outputId": "28abcb81-b35e-49c9-dd15-c26ed02c0454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - loss 0.3444 - val loss 0.3436\n",
            "\n",
            "Best validation loss: 0.3435823321342468\n",
            "\n",
            "Saving best model for epoch: 1\n",
            "\n",
            "Epoch 1 - loss 0.3522 - val loss 0.3298\n",
            "\n",
            "Best validation loss: 0.3298187851905823\n",
            "\n",
            "Saving best model for epoch: 2\n",
            "\n",
            "Epoch 2 - loss 0.3311 - val loss 0.3400\n",
            "Epoch 3 - loss 0.3526 - val loss 0.3335\n",
            "Epoch 4 - loss 0.3242 - val loss 0.3290\n",
            "\n",
            "Best validation loss: 0.32901954650878906\n",
            "\n",
            "Saving best model for epoch: 5\n",
            "\n",
            "Epoch 5 - loss 0.3425 - val loss 0.3366\n",
            "Epoch 6 - loss 0.3471 - val loss 0.3534\n",
            "Epoch 7 - loss 0.3332 - val loss 0.3502\n",
            "Epoch 8 - loss 0.3488 - val loss 0.3362\n",
            "Epoch 9 - loss 0.3239 - val loss 0.3346\n",
            "Epoch 10 - loss 0.3390 - val loss 0.3334\n",
            "Epoch 11 - loss 0.3517 - val loss 0.3512\n",
            "Epoch 12 - loss 0.3328 - val loss 0.3531\n",
            "Epoch 13 - loss 0.3403 - val loss 0.3478\n",
            "Epoch 14 - loss 0.3211 - val loss 0.3441\n",
            "Epoch 15 - loss 0.3445 - val loss 0.3343\n",
            "Epoch 16 - loss 0.3222 - val loss 0.3440\n",
            "Epoch 17 - loss 0.3465 - val loss 0.3327\n",
            "Epoch 18 - loss 0.3226 - val loss 0.3529\n",
            "Epoch 19 - loss 0.3485 - val loss 0.3354\n",
            "Epoch 20 - loss 0.3177 - val loss 0.3500\n",
            "Epoch 21 - loss 0.3479 - val loss 0.3330\n",
            "Epoch 22 - loss 0.3186 - val loss 0.3560\n",
            "Epoch 23 - loss 0.3508 - val loss 0.3353\n",
            "Epoch 24 - loss 0.3185 - val loss 0.3549\n",
            "Epoch 25 - loss 0.3511 - val loss 0.3361\n",
            "Epoch 26 - loss 0.3206 - val loss 0.3539\n",
            "Epoch 27 - loss 0.3481 - val loss 0.3408\n",
            "Epoch 28 - loss 0.3224 - val loss 0.3544\n",
            "Epoch 29 - loss 0.3388 - val loss 0.3498\n",
            "Epoch 30 - loss 0.3217 - val loss 0.3619\n",
            "Epoch 31 - loss 0.3290 - val loss 0.3597\n",
            "Epoch 32 - loss 0.3187 - val loss 0.3607\n",
            "We are at epoch: 32\n"
          ]
        }
      ],
      "source": [
        "train_fold(model, optimizer, criterion, loader, val_loader, n_epoch=300, verbose=1, sigma = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the best model checkpoint\n",
        "best_model_cp = torch.load('outputs_model_best_weights.pth')\n",
        "best_model_epoch = best_model_cp['epoch']\n",
        "print(f\"Best model was saved at {best_model_epoch} epochs\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVoKhXab_Cw-",
        "outputId": "d2b85fac-869b-47c9-b87e-7c58de4d8ff9"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model was saved at 5 epochs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_cp = torch.load('outputs_model_best_weights.pth')\n",
        "model.load_state_dict(best_model_cp['model_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niI4xrE8_l1F",
        "outputId": "e60f9008-0c67-434f-850b-1eedd7006a4f"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwyob_intHkB",
        "outputId": "3b5ae95b-cfc5-4f16-d447-ae1a0afafe36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6618773946360154\n"
          ]
        }
      ],
      "source": [
        "y_trues = []\n",
        "preds = []\n",
        "for val in val_loader:\n",
        "    model.eval()\n",
        "    y_true = val['y'].detach().numpy().tolist()\n",
        "    x = val['x'].to(device)\n",
        "\n",
        "    pred = model(x).detach().cpu().numpy().tolist()\n",
        "    y_trues.extend(y_true)\n",
        "    preds.extend(pred)\n",
        "\n",
        "auc = roc_auc_score(y_trues, preds)\n",
        "\n",
        "print(auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t4kjgMFtHkC"
      },
      "source": [
        "## 5-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:52.905566Z",
          "start_time": "2022-10-24T07:22:52.893435Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th4Cs0iqtHkC",
        "outputId": "9dde3b7c-f882-447e-940f-783151878772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set specifications\n",
            "---------------------------\n",
            "344 unique samples\n",
            "305 unique patients\n",
            "3 unique centers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3438: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# /!\\ we perform splits at the patient level so that all samples from the same patient\n",
        "# are found in the same split\n",
        "\n",
        "patients_unique = np.unique(patients_train)\n",
        "y_unique = np.array(\n",
        "    [np.mean(y_train[patients_train == p]) for p in patients_unique]\n",
        ")\n",
        "centers_unique = np.array(\n",
        "    [centers_train[patients_train == p][0] for p in patients_unique]\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Training set specifications\\n\"\n",
        "    \"---------------------------\\n\"\n",
        "    f\"{len(df_train)} unique samples\\n\"\n",
        "    f\"{len(patients_unique)} unique patients\\n\"\n",
        "    f\"{len(np.unique(centers_unique))} unique centers\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:54.077640Z",
          "start_time": "2022-10-24T07:22:52.907331Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BWyq3AqtHkC",
        "outputId": "5ee7cc76-b222-4619-df68-04c961cdd277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - loss 0.4213 - val loss 0.3531\n",
            "\n",
            "Best validation loss: 0.3531346917152405\n",
            "\n",
            "Saving best model for epoch: 1\n",
            "\n",
            "Epoch 1 - loss 0.3573 - val loss 0.3481\n",
            "\n",
            "Best validation loss: 0.3480828106403351\n",
            "\n",
            "Saving best model for epoch: 2\n",
            "\n",
            "Epoch 2 - loss 0.3367 - val loss 0.3318\n",
            "\n",
            "Best validation loss: 0.33182084560394287\n",
            "\n",
            "Saving best model for epoch: 3\n",
            "\n",
            "Epoch 3 - loss 0.3329 - val loss 0.3398\n",
            "Epoch 4 - loss 0.3632 - val loss 0.3963\n",
            "Epoch 5 - loss 0.3806 - val loss 0.3540\n",
            "Epoch 6 - loss 0.3225 - val loss 0.3301\n",
            "\n",
            "Best validation loss: 0.3301265239715576\n",
            "\n",
            "Saving best model for epoch: 7\n",
            "\n",
            "Epoch 7 - loss 0.3377 - val loss 0.3446\n",
            "Epoch 8 - loss 0.3629 - val loss 0.3421\n",
            "Epoch 9 - loss 0.3217 - val loss 0.3441\n",
            "Epoch 10 - loss 0.3343 - val loss 0.3339\n",
            "Epoch 11 - loss 0.3284 - val loss 0.3510\n",
            "Epoch 12 - loss 0.3437 - val loss 0.3368\n",
            "Epoch 13 - loss 0.3352 - val loss 0.3374\n",
            "Epoch 14 - loss 0.3533 - val loss 0.3715\n",
            "Epoch 15 - loss 0.3583 - val loss 0.3314\n",
            "Epoch 16 - loss 0.3481 - val loss 0.3489\n",
            "Epoch 17 - loss 0.3309 - val loss 0.3182\n",
            "\n",
            "Best validation loss: 0.31815633177757263\n",
            "\n",
            "Saving best model for epoch: 18\n",
            "\n",
            "Epoch 18 - loss 0.3334 - val loss 0.3209\n",
            "Epoch 19 - loss 0.3536 - val loss 0.3752\n",
            "Epoch 20 - loss 0.3768 - val loss 0.3424\n",
            "Epoch 21 - loss 0.3391 - val loss 0.3073\n",
            "\n",
            "Best validation loss: 0.3072921931743622\n",
            "\n",
            "Saving best model for epoch: 22\n",
            "\n",
            "Epoch 22 - loss 0.3317 - val loss 0.3434\n",
            "Epoch 23 - loss 0.3250 - val loss 0.3326\n",
            "Epoch 24 - loss 0.3403 - val loss 0.2728\n",
            "\n",
            "Best validation loss: 0.27278921008110046\n",
            "\n",
            "Saving best model for epoch: 25\n",
            "\n",
            "Epoch 25 - loss 0.3445 - val loss 0.3623\n",
            "Epoch 26 - loss 0.3365 - val loss 0.3364\n",
            "Epoch 27 - loss 0.3333 - val loss 0.3458\n",
            "Epoch 28 - loss 0.3460 - val loss 0.3500\n",
            "Epoch 29 - loss 0.3296 - val loss 0.3563\n",
            "Epoch 30 - loss 0.3414 - val loss 0.3359\n",
            "Epoch 31 - loss 0.3290 - val loss 0.3211\n",
            "Epoch 32 - loss 0.3801 - val loss 0.3380\n",
            "Epoch 33 - loss 0.3355 - val loss 0.4020\n",
            "Epoch 34 - loss 0.3580 - val loss 0.3506\n",
            "Epoch 35 - loss 0.3327 - val loss 0.3216\n",
            "Epoch 36 - loss 0.3324 - val loss 0.3607\n",
            "Epoch 37 - loss 0.3272 - val loss 0.3367\n",
            "Epoch 38 - loss 0.3549 - val loss 0.4005\n",
            "Epoch 39 - loss 0.3520 - val loss 0.3518\n",
            "Epoch 40 - loss 0.3423 - val loss 0.3523\n",
            "Epoch 41 - loss 0.3440 - val loss 0.3185\n",
            "Epoch 42 - loss 0.3313 - val loss 0.3280\n",
            "Epoch 43 - loss 0.3322 - val loss 0.3098\n",
            "Epoch 44 - loss 0.3444 - val loss 0.3426\n",
            "Epoch 45 - loss 0.3432 - val loss 0.3352\n",
            "Epoch 46 - loss 0.3194 - val loss 0.3203\n",
            "Epoch 47 - loss 0.3275 - val loss 0.4320\n",
            "Epoch 48 - loss 0.3362 - val loss 0.3374\n",
            "Epoch 49 - loss 0.3203 - val loss 0.3374\n",
            "Epoch 50 - loss 0.3377 - val loss 0.3384\n",
            "Epoch 51 - loss 0.3101 - val loss 0.4325\n",
            "Epoch 52 - loss 0.3355 - val loss 0.3585\n",
            "Epoch 53 - loss 0.3331 - val loss 0.3481\n",
            "We are at epoch: 53\n",
            "AUC on split 0 fold 0: 0.576\n",
            "Epoch 0 - loss 0.3464 - val loss 0.4000\n",
            "\n",
            "Best validation loss: 0.4000368118286133\n",
            "\n",
            "Saving best model for epoch: 1\n",
            "\n",
            "Epoch 1 - loss 0.3332 - val loss 0.3051\n",
            "\n",
            "Best validation loss: 0.3050639033317566\n",
            "\n",
            "Saving best model for epoch: 2\n",
            "\n",
            "Epoch 2 - loss 0.3604 - val loss 0.3440\n",
            "Epoch 3 - loss 0.3415 - val loss 0.3110\n",
            "Epoch 4 - loss 0.3401 - val loss 0.3348\n",
            "Epoch 5 - loss 0.3392 - val loss 0.2972\n",
            "\n",
            "Best validation loss: 0.29721638560295105\n",
            "\n",
            "Saving best model for epoch: 6\n",
            "\n",
            "Epoch 6 - loss 0.3306 - val loss 0.3135\n",
            "Epoch 7 - loss 0.3475 - val loss 0.3143\n",
            "Epoch 8 - loss 0.3407 - val loss 0.3446\n",
            "Epoch 9 - loss 0.3429 - val loss 0.3275\n",
            "Epoch 10 - loss 0.3450 - val loss 0.3976\n",
            "Epoch 11 - loss 0.3466 - val loss 0.3442\n",
            "Epoch 12 - loss 0.3706 - val loss 0.3121\n",
            "Epoch 13 - loss 0.3780 - val loss 0.2944\n",
            "\n",
            "Best validation loss: 0.2944173216819763\n",
            "\n",
            "Saving best model for epoch: 14\n",
            "\n",
            "Epoch 14 - loss 0.3359 - val loss 0.3364\n",
            "Epoch 15 - loss 0.3482 - val loss 0.3425\n",
            "Epoch 16 - loss 0.3462 - val loss 0.3045\n",
            "Epoch 17 - loss 0.3329 - val loss 0.3372\n",
            "Epoch 18 - loss 0.3828 - val loss 0.3827\n",
            "Epoch 19 - loss 0.3423 - val loss 0.3135\n",
            "Epoch 20 - loss 0.3632 - val loss 0.3513\n",
            "Epoch 21 - loss 0.3665 - val loss 0.3756\n",
            "Epoch 22 - loss 0.3512 - val loss 0.3467\n",
            "Epoch 23 - loss 0.3428 - val loss 0.2893\n",
            "\n",
            "Best validation loss: 0.2892763614654541\n",
            "\n",
            "Saving best model for epoch: 24\n",
            "\n",
            "Epoch 24 - loss 0.3254 - val loss 0.3264\n",
            "Epoch 25 - loss 0.3221 - val loss 0.3159\n",
            "Epoch 26 - loss 0.3349 - val loss 0.3852\n",
            "Epoch 27 - loss 0.3295 - val loss 0.3520\n",
            "Epoch 28 - loss 0.3500 - val loss 0.3172\n",
            "Epoch 29 - loss 0.3394 - val loss 0.3521\n"
          ]
        }
      ],
      "source": [
        "aucs = []\n",
        "models = []\n",
        "# 5-fold CV is repeated 5 times with different random states\n",
        "for k in range(5):\n",
        "    kfold = StratifiedKFold(5, shuffle=True, random_state=k)\n",
        "    fold = 0\n",
        "    # split is performed at the patient-level\n",
        "    for train_idx_, val_idx_ in kfold.split(patients_unique, y_unique):\n",
        "        # retrieve the indexes of the samples corresponding to the\n",
        "        # patients in `train_idx_` and `test_idx_`\n",
        "        train_idx = np.arange(len(df_train))[\n",
        "            pd.Series(patients_train).isin(patients_unique[train_idx_])\n",
        "        ]\n",
        "        val_idx = np.arange(len(df_train))[\n",
        "            pd.Series(patients_train).isin(patients_unique[val_idx_])\n",
        "        ]\n",
        "        # set the training and validation folds\n",
        "        df_fold_train = df_train.iloc[train_idx]\n",
        "        data_fold_train = MyDataset(df_fold_train, train_features_dir)\n",
        "        loader_fold_train = DataLoader(data_fold_train, batch_size=40, shuffle=True)\n",
        "\n",
        "        df_fold_val = df_train.iloc[val_idx]\n",
        "        data_fold_val = MyDataset(df_fold_val, train_features_dir)\n",
        "        loader_fold_val = DataLoader(data_fold_val, batch_size=40, shuffle=True)\n",
        "        \n",
        "        # instantiate the model\n",
        "        model = Perceptron().to(device)\n",
        "        criterion = BCELoss().to(device)\n",
        "        optimizer = Adam(model.parameters(), lr=0.01, weight_decay=1e-1)\n",
        "        \n",
        "        model_name = f'MLP_{k}_{fold}'\n",
        "        train_fold(model, optimizer, criterion, loader_fold_train, val_loader=loader_fold_val, n_epoch=300, sigma=0.001, model_name=model_name)\n",
        "\n",
        "        best_model_cp = torch.load('outputs_'+ model_name + '_best_weights.pth')\n",
        "        model.load_state_dict(best_model_cp['model_state_dict'])\n",
        "        \n",
        "        # get the predictions (1-d probability)\n",
        "        y_trues = []\n",
        "        preds = []\n",
        "        for val in loader_fold_val:\n",
        "            model.eval()\n",
        "            y_true = val['y'].detach().cpu().numpy().tolist()\n",
        "            x = val['x'].to(device)\n",
        "\n",
        "            pred = model(x).detach().cpu().numpy().tolist()\n",
        "            y_trues.extend(y_true)\n",
        "            preds.extend(pred)\n",
        "\n",
        "        auc = roc_auc_score(y_trues, preds)\n",
        "\n",
        "        print(f\"AUC on split {k} fold {fold}: {auc:.3f}\")\n",
        "        aucs.append(auc)\n",
        "        # add the logistic regression to the list of classifiers\n",
        "        models.append(model)\n",
        "        fold += 1\n",
        "    print(\"----------------------------\")\n",
        "print(\n",
        "    f\"5-fold cross-validated AUC averaged over {k+1} repeats: \"\n",
        "    f\"{np.mean(aucs):.3f} ({np.std(aucs):.3f})\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5QBiOMltHkD"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXszLbxWtHkD"
      },
      "source": [
        "Now we evaluate the previous models trained through cross-validation so that to produce a submission file that can directly be uploaded on the data challenge platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WLw6VpwtHkD"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "T97MdixbxVfU",
        "outputId": "6ee4004c-0008-4b0b-a66c-f75809c150b3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sample ID Patient ID Center ID\n",
              "0    ID_003.npy      P_003       C_3\n",
              "1    ID_004.npy      P_004       C_4\n",
              "2    ID_008.npy      P_008       C_4\n",
              "3    ID_009.npy      P_009       C_4\n",
              "4    ID_010.npy      P_010       C_3\n",
              "..          ...        ...       ...\n",
              "144  ID_482.npy      P_445       C_3\n",
              "145  ID_487.npy      P_449       C_3\n",
              "146  ID_488.npy      P_450       C_4\n",
              "147  ID_492.npy      P_453       C_4\n",
              "148  ID_493.npy      P_454       C_3\n",
              "\n",
              "[149 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6b9e5b0-53b6-4498-840b-e7d340974470\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample ID</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Center ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_003.npy</td>\n",
              "      <td>P_003</td>\n",
              "      <td>C_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_004.npy</td>\n",
              "      <td>P_004</td>\n",
              "      <td>C_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_008.npy</td>\n",
              "      <td>P_008</td>\n",
              "      <td>C_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_009.npy</td>\n",
              "      <td>P_009</td>\n",
              "      <td>C_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_010.npy</td>\n",
              "      <td>P_010</td>\n",
              "      <td>C_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>ID_482.npy</td>\n",
              "      <td>P_445</td>\n",
              "      <td>C_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>ID_487.npy</td>\n",
              "      <td>P_449</td>\n",
              "      <td>C_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>ID_488.npy</td>\n",
              "      <td>P_450</td>\n",
              "      <td>C_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>ID_492.npy</td>\n",
              "      <td>P_453</td>\n",
              "      <td>C_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>ID_493.npy</td>\n",
              "      <td>P_454</td>\n",
              "      <td>C_3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6b9e5b0-53b6-4498-840b-e7d340974470')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6b9e5b0-53b6-4498-840b-e7d340974470 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6b9e5b0-53b6-4498-840b-e7d340974470');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:54.987815Z",
          "start_time": "2022-10-24T07:22:54.079916Z"
        },
        "id": "SZPmMi50tHkD"
      },
      "outputs": [],
      "source": [
        "dataset_test = MyDataset(df_test, test_features_dir, test=True)\n",
        "\n",
        "loader_test = DataLoader(dataset_test, batch_size=20, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Xi_VmNkyw44D",
        "outputId": "f2dead46-24a9-42eb-d27a-943d242efbf4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-ff882bad8e97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-39d00b0ecc2b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# load the coordinates and features (1000, 3+2048)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0m_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# get coordinates (zoom level, tile x-coord on the slide, tile y-coord on the slide)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# and the MoCo V2 features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_input/moco_features/ID_002.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T08:17:35.617554Z",
          "start_time": "2022-10-20T08:17:35.603562Z"
        },
        "id": "O9GbDCC4tHkE"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:55.043255Z",
          "start_time": "2022-10-24T07:22:54.989274Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "6i0le2B2tHkE",
        "outputId": "12e86102-131b-49ec-e1a9-aeb7122238da"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-e37d84a57b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-3144e9a0c0a7>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# load the coordinates and features (1000, 3+2048)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0m_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# get coordinates (zoom level, tile x-coord on the slide, tile y-coord on the slide)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# and the MoCo V2 features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not Series"
          ]
        }
      ],
      "source": [
        "preds_test = 0\n",
        "\n",
        "\n",
        "# loop over the classifiers\n",
        "for lr in models:\n",
        "    \n",
        "    preds = []\n",
        "    for val in loader_test:\n",
        "        model.eval()\n",
        "        x = val['x'].to(device)\n",
        "\n",
        "        pred = model(x).detach().numpy().tolist()\n",
        "        preds.extend(pred)\n",
        "\n",
        "    preds = np.array(preds)\n",
        "    preds_test += preds\n",
        "# and take the average (ensembling technique)\n",
        "preds_test = preds_test / len(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Ax63WHtHkE"
      },
      "source": [
        "## Saving predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:22:55.098571Z",
          "start_time": "2022-10-24T07:22:55.044975Z"
        },
        "id": "of-SNwlhtHkF"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame(\n",
        "    {\"Sample ID\": df_test[\"Sample ID\"].values, \"Target\": preds_test}\n",
        ").sort_values(\n",
        "    \"Sample ID\"\n",
        ")  # extra step to sort the sample IDs\n",
        "\n",
        "# sanity checks\n",
        "assert all(submission[\"Target\"].between(0, 1)), \"`Target` values must be in [0, 1]\"\n",
        "assert submission.shape == (149, 2), \"Your submission file must be of shape (149, 2)\"\n",
        "assert list(submission.columns) == [\n",
        "    \"Sample ID\",\n",
        "    \"Target\",\n",
        "], \"Your submission file must have columns `Sample ID` and `Target`\"\n",
        "\n",
        "# save the submission as a csv file\n",
        "submission.to_csv(data_dir / \"benchmark_test_output.csv\", index=None)\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBZDlA_QtHkF"
      },
      "source": [
        "# Dealing with images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4N09eRLtHkF"
      },
      "source": [
        "The following code aims to load and manipulate the images provided as part of  this challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo0uzTl-tHkG"
      },
      "source": [
        "## Scanning images paths on disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhkZ3RDftHkG"
      },
      "source": [
        "This operation can take up to 5 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:00.263580Z",
          "start_time": "2022-10-24T07:22:55.100342Z"
        },
        "id": "nRB1V26ktHkG"
      },
      "outputs": [],
      "source": [
        "train_images_dir = data_dir / \"train_input\" / \"images\"\n",
        "train_images_files = list(train_images_dir.rglob(\"*.jpg\"))\n",
        "\n",
        "test_images_dir = data_dir / \"test_input\" / \"images\"\n",
        "test_images_files = list(test_images_dir.rglob(\"*.jpg\"))\n",
        "\n",
        "print(\n",
        "    f\"Number of images\\n\"\n",
        "    \"-----------------\\n\"\n",
        "    f\"Train: {len(train_images_files)}\\n\" # 344 x 1000 = 344,000 tiles\n",
        "    f\"Test: {len(test_images_files)}\\n\"  # 149 x 1000 = 149,000 tiles\n",
        "    f\"Total: {len(train_images_files) + len(test_images_files)}\\n\"  # 493 x 1000 = 493,000 tiles\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-20T10:16:48.078600Z",
          "start_time": "2022-10-20T10:16:47.948127Z"
        },
        "id": "nHmmEQx4tHkH"
      },
      "source": [
        "## Reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vULU7SitHkH"
      },
      "source": [
        "Now we can load some of the `.jpg` images for a given sample, say `ID_001`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:00.381225Z",
          "start_time": "2022-10-24T07:23:00.267047Z"
        },
        "id": "rLyRuEe8tHkI"
      },
      "outputs": [],
      "source": [
        "ID_001_tiles = [p for p in train_images_files if 'ID_001' in p.name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:01.973155Z",
          "start_time": "2022-10-24T07:23:00.382760Z"
        },
        "id": "P4E6K-mMtHkI"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(5, 5)\n",
        "fig.set_size_inches(12, 12)\n",
        "\n",
        "for i, img_file in enumerate(ID_001_tiles[:25]):\n",
        "    # get the metadata from the file path\n",
        "    _, metadata = str(img_file).split(\"tile_\")\n",
        "    id_tile, level, x, y = metadata[:-4].split(\"_\")\n",
        "    img = plt.imread(img_file)\n",
        "    ax = axes[i//5, i%5]\n",
        "    ax.imshow(img)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_title(f\"Tile {id_tile} ({x}, {y})\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iEVWY8otHkI"
      },
      "source": [
        "## Mapping with features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM6yjhS1tHkJ"
      },
      "source": [
        "Note that the coordinates in the features matrices and tiles number are aligned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:01.984327Z",
          "start_time": "2022-10-24T07:23:01.974933Z"
        },
        "id": "iAoTnjxLtHkJ"
      },
      "outputs": [],
      "source": [
        "sample = \"ID_001.npy\"\n",
        "_features = np.load(train_features_dir / sample)\n",
        "coordinates, features = _features[:, :3], _features[:, 3:]\n",
        "print(\"xy features coordinates\")\n",
        "coordinates[:10, 1:].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-24T07:23:01.990342Z",
          "start_time": "2022-10-24T07:23:01.985926Z"
        },
        "id": "IrAp_y9dtHkK"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    \"Tiles numbering and features coordinates\\n\"\n",
        ")\n",
        "[tile.name for tile in ID_001_tiles[:10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP_5IxWNtHkK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHgk7DOxtHkK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}